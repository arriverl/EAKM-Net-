# EAKM-Net 使用说明

## 目录

1. [环境配置](#1-环境配置)
2. [数据准备](#2-数据准备)
3. [模型训练](#3-模型训练)
4. [模型评估](#4-模型评估)
5. [模型推理](#5-模型推理)
6. [常见问题](#6-常见问题)

---

## 1. 环境配置

### 1.1 安装Python依赖

```bash
pip install -r requirements.txt
```

### 1.2 安装spaCy模型（用于实体识别）

**英文模型**：
```bash
python -m spacy download en_core_web_sm
```

**中文模型**（如果使用中文数据）：
```bash
python -m spacy download zh_core_web_sm
```

### 1.3 验证安装

```python
import torch
import transformers
import spacy

print(f"PyTorch版本: {torch.__version__}")
print(f"Transformers版本: {transformers.__version__}")

# 测试spaCy
try:
    nlp = spacy.load("en_core_web_sm")
    print("spaCy模型加载成功")
except:
    print("spaCy模型未安装")
```

---

## 2. 数据准备

### 2.1 数据格式

数据文件应为CSV格式，包含以下列：

| 列名 | 说明 | 示例 |
|------|------|------|
| `text` | 新闻文本内容 | "This is a news article..." |
| `image` | 图像文件路径（相对或绝对路径） | "./images/1.jpg" |
| `label` | 标签（0=真实，1=虚假） | 0 |

### 2.2 数据目录结构

```
data/
├── fake_news.csv          # 数据文件
├── images/                # 图像文件夹
│   ├── 1.jpg
│   ├── 2.jpg
│   └── ...
└── test.csv               # 测试数据（可选）
```

### 2.3 数据示例

```csv
text,image,label
"Breaking news: Scientists discover new planet...","./images/1.jpg",0
"Fake news: Celebrity arrested for fraud...","./images/2.jpg",1
"Real story: Company announces new product...","./images/3.jpg",0
```

### 2.4 数据预处理

数据加载器会自动进行以下预处理：
- 文本清洗（移除HTML标签、URL等）
- 图像缩放和归一化
- 实体识别（使用spaCy）

---

## 3. 模型训练

### 3.1 基本训练命令

```bash
python train.py \
    --data_path ./data/fake_news.csv \
    --model_save_dir ./checkpoints \
    --batch_size 4 \
    --num_epochs 50 \
    --learning_rate 2e-5
```

### 3.2 完整训练参数

```bash
python train.py \
    --data_path ./data/fake_news.csv \
    --model_save_dir ./checkpoints \
    --batch_size 4 \
    --num_epochs 50 \
    --learning_rate 2e-5 \
    --text_model bert-base-uncased \
    --image_backbone resnet50 \
    --device cuda \
    --resume_from ./checkpoints/checkpoint_epoch_10.pth
```

### 3.3 参数说明

| 参数 | 说明 | 默认值 |
|------|------|--------|
| `--data_path` | 数据文件路径（必需） | - |
| `--model_save_dir` | 模型保存目录 | `./checkpoints` |
| `--batch_size` | 批次大小 | 4 |
| `--num_epochs` | 训练轮数 | 50 |
| `--learning_rate` | 学习率 | 2e-5 |
| `--text_model` | 文本模型 | `bert-base-uncased` |
| `--image_backbone` | 图像骨干网络 | `resnet50` |
| `--device` | 设备（cuda/cpu） | `cuda` |
| `--resume_from` | 恢复训练的检查点路径 | None |

### 3.4 训练过程

训练过程中会显示：
- 每个epoch的训练损失和准确率
- 验证集的性能指标（准确率、精确率、召回率、F1、AUC）
- 最佳模型会自动保存

### 3.5 检查点文件

训练过程中会生成：
- `best_model.pth`：最佳模型（基于验证集AUC）
- `checkpoint_epoch_N.pth`：定期保存的检查点

---

## 4. 模型评估

### 4.1 基本评估命令

```bash
python evaluate.py \
    --model_path ./checkpoints/best_model.pth \
    --data_path ./data/test.csv \
    --output_dir ./results
```

### 4.2 完整评估参数

```bash
python evaluate.py \
    --model_path ./checkpoints/best_model.pth \
    --data_path ./data/test.csv \
    --batch_size 4 \
    --text_model bert-base-uncased \
    --image_backbone resnet50 \
    --device cuda \
    --output_dir ./results
```

### 4.3 评估结果

评估脚本会生成：
- `evaluation_results.txt`：文本格式的评估结果
- `confusion_matrix.png`：混淆矩阵可视化
- `roc_curve.png`：ROC曲线

### 4.4 评估指标

- **准确率（Accuracy）**：正确分类的比例
- **精确率（Precision）**：预测为虚假中真正是虚假的比例
- **召回率（Recall）**：所有虚假新闻中被正确识别的比例
- **F1分数（F1-Score）**：精确率和召回率的调和平均
- **AUC**：ROC曲线下面积

---

## 5. 模型推理

### 5.1 Python API使用

```python
import torch
from fake_news_detection import create_eakm_net
from fake_news_detection.data_preprocessing import ImagePreprocessor

# 加载模型
model = create_eakm_net(
    text_model='bert-base-uncased',
    image_backbone='resnet50',
    num_classes=2
)
checkpoint = torch.load('./checkpoints/best_model.pth')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# 预处理图像
image_preprocessor = ImagePreprocessor(image_size=224)
image = image_preprocessor.preprocess('./images/test.jpg')

# 准备输入
texts = ["This is a test news article..."]
images = image.unsqueeze(0)  # 添加batch维度
entities = [["test", "news"]]  # 实体列表（可选）

# 预测
with torch.no_grad():
    logits = model(texts, images, entities)
    probs = torch.softmax(logits, dim=1)
    prediction = torch.argmax(logits, dim=1).item()

print(f"预测类别: {'虚假' if prediction == 1 else '真实'}")
print(f"置信度: {probs[0][prediction].item():.4f}")
```

### 5.2 批量推理

```python
from fake_news_detection.data_preprocessing import FakeNewsDataset
from torch.utils.data import DataLoader

# 加载数据集
dataset = FakeNewsDataset(
    data_path='./data/test.csv',
    text_col='text',
    image_col='image',
    label_col='label'
)

# 创建数据加载器
dataloader = DataLoader(dataset, batch_size=4, shuffle=False)

# 批量预测
all_predictions = []
for batch in dataloader:
    texts = batch['text']
    images = batch['image'].to(device)
    entities = batch['entities']
    
    with torch.no_grad():
        logits = model(texts, images, entities)
        predictions = torch.argmax(logits, dim=1)
        all_predictions.extend(predictions.cpu().numpy())
```

---

## 6. 常见问题

### Q1: 内存不足（Out of Memory）

**解决方案**：
1. 减小batch_size（如改为2或1）
2. 使用更小的模型（如bert-base-uncased）
3. 减少图像分辨率（修改image_size参数）
4. 使用梯度累积

```python
# 梯度累积示例
accumulation_steps = 4
for i, batch in enumerate(dataloader):
    loss = model(batch) / accumulation_steps
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

### Q2: 训练速度慢

**解决方案**：
1. 使用GPU（设置`--device cuda`）
2. 冻结部分层（如冻结BERT的前几层）
3. 使用混合精度训练

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    logits = model(texts, images, entities)
    loss = criterion(logits, labels)
scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

### Q3: 实体识别失败

**解决方案**：
1. 确保已安装spaCy模型：`python -m spacy download en_core_web_sm`
2. 检查文本语言是否匹配模型语言
3. 如果实体识别失败，模型仍可运行（使用空实体列表）

### Q4: 图像加载失败

**解决方案**：
1. 检查图像路径是否正确
2. 确保图像文件存在且可读
3. 检查图像格式（支持JPG、PNG等）
4. 如果图像不存在，会自动使用空白图像

### Q5: 知识库查询失败

**解决方案**：
1. 当前使用模拟知识库，无需额外配置
2. 如需使用真实知识库，需要：
   - 配置Wikidata API
   - 或提供本地知识库文件

### Q6: 中文支持

**使用中文模型**：
```python
# 训练时指定中文模型
python train.py \
    --text_model bert-base-chinese \
    ...

# 代码中使用中文spaCy模型
from fake_news_detection.data_preprocessing import EntityRecognizer
recognizer = EntityRecognizer(model_name='zh_core_web_sm')
```

### Q7: 自定义知识库

**修改知识库**：
```python
from fake_news_detection.knowledge_enhancement import KnowledgeBase

# 创建自定义知识库
kb = KnowledgeBase()
kb.knowledge = {
    ("实体1", "关系", "实体2"): 1.0,  # 真实
    ("实体3", "关系", "实体4"): 0.0,  # 虚假
}

# 或从文件加载
kb.load_from_file('./knowledge_base.json')
```

---

## 7. 性能优化建议

1. **数据预处理**：
   - 预先处理图像，避免训练时重复处理
   - 使用多进程数据加载（`num_workers>0`）

2. **模型优化**：
   - 使用知识蒸馏压缩模型
   - 量化模型以减少内存占用

3. **训练优化**：
   - 使用学习率调度器
   - 早停（Early Stopping）防止过拟合
   - 数据增强提高泛化能力

---

## 8. 联系与支持

如有问题，请：
1. 查看项目README
2. 查看课程报告文档
3. 提交Issue或联系项目维护者

---

**祝使用愉快！**








